{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre: **05_modelo_edad**\n",
    "#### Autores: _Sergio Cañón  Laiz y Ignacio Ruiz de Zuazu Echavarría_\n",
    "#### CUNEF\n",
    "#### 15/01/2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerías \n",
    "\n",
    "import numpy as np  # álgebra lineal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import glob  # pathnames\n",
    "import cv2  # lectura y procesamiento de las imagenes\n",
    "\n",
    "import matplotlib.pyplot as plt  # gráficos\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os  # lectura de directorios\n",
    "\n",
    "import keras \n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import time #tiempos de ejecución\n",
    "from random import shuffle\n",
    "from keras.preprocessing import image\n",
    "import imageio\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_labels_age = np.load(r'..\\data\\04_data_array\\categorical_labels_age.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(r'..\\data\\04_data_array\\data_32_32_rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La longuitud del los datos son de: 24099\n"
     ]
    }
   ],
   "source": [
    "size = len(X)\n",
    "print(\"La longuitud del los datos son de:\", size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos un 30% de las iamgenes como test y el 70% como train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion train y test set\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (X[:15008],categorical_labels_age[:15008]) , (X[15008:] , categorical_labels_age[15008:])\n",
    "(x_valid , y_valid) = (x_test[:7000], y_test[:7000])\n",
    "(x_test, y_test) = (x_test[7000:], y_test[7000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagenes en el train: 15008\n",
      "Número de imagenes en el test: 2091\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de imagenes en el train:\",x_train.shape[0])\n",
    "print(\"Número de imagenes en el test:\",x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "## SGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 256)       3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16, 16, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 50)        25650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 882,615\n",
      "Trainable params: 882,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "151/151 [==============================] - 184s 1s/step - loss: 1.6083 - accuracy: 0.2140 - auc: 0.5253 - categorical_accuracy: 0.2140 - val_loss: 1.6004 - val_accuracy: 0.2710 - val_auc: 0.5721 - val_categorical_accuracy: 0.2710\n",
      "Epoch 2/25\n",
      "151/151 [==============================] - 196s 1s/step - loss: 1.5971 - accuracy: 0.2432 - auc: 0.5501 - categorical_accuracy: 0.2432 - val_loss: 1.5939 - val_accuracy: 0.2831 - val_auc: 0.5902 - val_categorical_accuracy: 0.2831\n",
      "Epoch 3/25\n",
      "151/151 [==============================] - 204s 1s/step - loss: 1.5922 - accuracy: 0.2552 - auc: 0.5614 - categorical_accuracy: 0.2552 - val_loss: 1.5916 - val_accuracy: 0.2966 - val_auc: 0.6013 - val_categorical_accuracy: 0.2966\n",
      "Epoch 4/25\n",
      "151/151 [==============================] - 275s 2s/step - loss: 1.5849 - accuracy: 0.2639 - auc: 0.5748 - categorical_accuracy: 0.2639 - val_loss: 1.5829 - val_accuracy: 0.3071 - val_auc: 0.6121 - val_categorical_accuracy: 0.3071\n",
      "Epoch 5/25\n",
      "151/151 [==============================] - 271s 2s/step - loss: 1.5747 - accuracy: 0.2723 - auc: 0.5880 - categorical_accuracy: 0.2723 - val_loss: 1.5678 - val_accuracy: 0.2869 - val_auc: 0.6039 - val_categorical_accuracy: 0.2869\n",
      "Epoch 6/25\n",
      "151/151 [==============================] - 265s 2s/step - loss: 1.5700 - accuracy: 0.2763 - auc: 0.5922 - categorical_accuracy: 0.2763 - val_loss: 1.5706 - val_accuracy: 0.3166 - val_auc: 0.6183 - val_categorical_accuracy: 0.3166\n",
      "Epoch 7/25\n",
      "151/151 [==============================] - 267s 2s/step - loss: 1.5624 - accuracy: 0.2908 - auc: 0.6017 - categorical_accuracy: 0.2908 - val_loss: 1.5533 - val_accuracy: 0.3201 - val_auc: 0.6275 - val_categorical_accuracy: 0.3201\n",
      "Epoch 8/25\n",
      "151/151 [==============================] - 257s 2s/step - loss: 1.5556 - accuracy: 0.2920 - auc: 0.6082 - categorical_accuracy: 0.2920 - val_loss: 1.5421 - val_accuracy: 0.3230 - val_auc: 0.6325 - val_categorical_accuracy: 0.3230\n",
      "Epoch 9/25\n",
      "151/151 [==============================] - 189s 1s/step - loss: 1.5506 - accuracy: 0.2975 - auc: 0.6134 - categorical_accuracy: 0.2975 - val_loss: 1.5351 - val_accuracy: 0.3140 - val_auc: 0.6326 - val_categorical_accuracy: 0.3140\n",
      "Epoch 10/25\n",
      "151/151 [==============================] - 182s 1s/step - loss: 1.5448 - accuracy: 0.3085 - auc: 0.6201 - categorical_accuracy: 0.3085 - val_loss: 1.5316 - val_accuracy: 0.3363 - val_auc: 0.6440 - val_categorical_accuracy: 0.3363\n",
      "Epoch 11/25\n",
      "151/151 [==============================] - 198s 1s/step - loss: 1.5389 - accuracy: 0.3112 - auc: 0.6258 - categorical_accuracy: 0.3112 - val_loss: 1.5275 - val_accuracy: 0.3383 - val_auc: 0.6482 - val_categorical_accuracy: 0.3383\n",
      "Epoch 12/25\n",
      "151/151 [==============================] - 191s 1s/step - loss: 1.5333 - accuracy: 0.3158 - auc: 0.6320 - categorical_accuracy: 0.3158 - val_loss: 1.5484 - val_accuracy: 0.2963 - val_auc: 0.6230 - val_categorical_accuracy: 0.2963\n",
      "Epoch 13/25\n",
      "151/151 [==============================] - 191s 1s/step - loss: 1.5282 - accuracy: 0.3182 - auc: 0.6358 - categorical_accuracy: 0.3182 - val_loss: 1.5180 - val_accuracy: 0.3423 - val_auc: 0.6562 - val_categorical_accuracy: 0.3423\n",
      "Epoch 14/25\n",
      "151/151 [==============================] - 191s 1s/step - loss: 1.5232 - accuracy: 0.3226 - auc: 0.6408 - categorical_accuracy: 0.3226 - val_loss: 1.5169 - val_accuracy: 0.3474 - val_auc: 0.6581 - val_categorical_accuracy: 0.3474\n",
      "Epoch 15/25\n",
      "151/151 [==============================] - 195s 1s/step - loss: 1.5196 - accuracy: 0.3223 - auc: 0.6438 - categorical_accuracy: 0.3223 - val_loss: 1.5027 - val_accuracy: 0.3419 - val_auc: 0.6607 - val_categorical_accuracy: 0.3419\n",
      "Epoch 16/25\n",
      "151/151 [==============================] - 190s 1s/step - loss: 1.5132 - accuracy: 0.3320 - auc: 0.6499 - categorical_accuracy: 0.3320 - val_loss: 1.5061 - val_accuracy: 0.3526 - val_auc: 0.6659 - val_categorical_accuracy: 0.3526\n",
      "Epoch 17/25\n",
      "151/151 [==============================] - 183s 1s/step - loss: 1.5092 - accuracy: 0.3374 - auc: 0.6542 - categorical_accuracy: 0.3374 - val_loss: 1.4997 - val_accuracy: 0.3606 - val_auc: 0.6700 - val_categorical_accuracy: 0.3606\n",
      "Epoch 18/25\n",
      "151/151 [==============================] - 204s 1s/step - loss: 1.5042 - accuracy: 0.3384 - auc: 0.6577 - categorical_accuracy: 0.3384 - val_loss: 1.4948 - val_accuracy: 0.3473 - val_auc: 0.6692 - val_categorical_accuracy: 0.3473\n",
      "Epoch 19/25\n",
      "151/151 [==============================] - 192s 1s/step - loss: 1.5003 - accuracy: 0.3424 - auc: 0.6601 - categorical_accuracy: 0.3424 - val_loss: 1.4903 - val_accuracy: 0.3470 - val_auc: 0.6684 - val_categorical_accuracy: 0.3470\n",
      "Epoch 20/25\n",
      "151/151 [==============================] - 97s 644ms/step - loss: 1.4967 - accuracy: 0.3430 - auc: 0.6636 - categorical_accuracy: 0.3430 - val_loss: 1.4766 - val_accuracy: 0.3580 - val_auc: 0.6786 - val_categorical_accuracy: 0.3580\n",
      "Epoch 21/25\n",
      "151/151 [==============================] - 89s 592ms/step - loss: 1.4965 - accuracy: 0.3428 - auc: 0.6634 - categorical_accuracy: 0.3428 - val_loss: 1.4815 - val_accuracy: 0.3491 - val_auc: 0.6722 - val_categorical_accuracy: 0.3491\n",
      "Epoch 22/25\n",
      "151/151 [==============================] - 88s 583ms/step - loss: 1.4901 - accuracy: 0.3497 - auc: 0.6683 - categorical_accuracy: 0.3497 - val_loss: 1.5000 - val_accuracy: 0.3681 - val_auc: 0.6708 - val_categorical_accuracy: 0.3681\n",
      "Epoch 23/25\n",
      "151/151 [==============================] - 88s 583ms/step - loss: 1.4840 - accuracy: 0.3531 - auc: 0.6730 - categorical_accuracy: 0.3531 - val_loss: 1.4651 - val_accuracy: 0.3637 - val_auc: 0.6857 - val_categorical_accuracy: 0.3637\n",
      "Epoch 24/25\n",
      "151/151 [==============================] - 91s 600ms/step - loss: 1.4810 - accuracy: 0.3566 - auc: 0.6747 - categorical_accuracy: 0.3566 - val_loss: 1.4633 - val_accuracy: 0.3777 - val_auc: 0.6903 - val_categorical_accuracy: 0.3777\n",
      "Epoch 25/25\n",
      "151/151 [==============================] - 95s 628ms/step - loss: 1.4794 - accuracy: 0.3595 - auc: 0.6756 - categorical_accuracy: 0.3595 - val_loss: 1.4581 - val_accuracy: 0.3740 - val_auc: 0.6904 - val_categorical_accuracy: 0.3740\n"
     ]
    }
   ],
   "source": [
    "model_sgd_gender = tf.keras.Sequential()\n",
    "\n",
    "# Primera capa de la CNN. El imput debe ajsutarse al tamañ ode la imagen (32 x 32 y 3 de los colores)\n",
    "\n",
    "model_sgd_age.add(tf.keras.layers.Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3))) \n",
    "model_sgd_age.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_sgd_age.add(tf.keras.layers.Dropout(0.3))\n",
    "model_sgd_age.add(tf.keras.layers.Dense(128, activation='relu')) \n",
    "\n",
    "model_sgd_age.add(tf.keras.layers.Conv2D(filters=50, kernel_size=2, padding='same', activation='relu')) \n",
    "model_sgd_age.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# drop out= eliminamos el 30% de las imagenes para evitar overfitting\n",
    "model_sgd_age.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_sgd_age.add(tf.keras.layers.Flatten())\n",
    "model_sgd_age.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "# drop out= eliminamos la mitad de las imagenes para evitar overfitting\n",
    "model_sgd_age.add(tf.keras.layers.Dropout(0.5)) \n",
    "\n",
    "\n",
    "# nuestro data set tiene 5 opciones de raza luego la última capa = 5\n",
    "\n",
    "model_sgd_age.add(tf.keras.layers.Dense(5, activation='softmax')) \n",
    "\n",
    "\n",
    "# Resumen del modelo\n",
    "model_sgd_age.summary()\n",
    "\n",
    "model_sgd_age.compile(loss='categorical_crossentropy',\n",
    "             optimizer=SGD(),\n",
    "             metrics=['accuracy','AUC','categorical_accuracy'])\n",
    "\n",
    "h_model_sgd_age = model_sgd_gender.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=100,\n",
    "         epochs=25,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Apuntes\\\\Desktop\\\\labUTKfaces\\\\models\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_sgd_age_history = h_model_sgd_age.history\n",
    "json.dump(model_sgd_age_history, open(\"../models/model_sgd_age_history.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Apuntes\\anaconda\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Apuntes\\anaconda\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../models/model_sgd_age_rgb.h\\assets\n"
     ]
    }
   ],
   "source": [
    "model_sgd_age.save('../models/model_sgd_age_rgb.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_test_edad.npy', x_test)\n",
    "np.save('y_test_edad.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16, 16, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 256)       131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               2097280   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,265,477\n",
      "Trainable params: 2,265,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "151/151 [==============================] - 251s 2s/step - loss: 1.5690 - accuracy: 0.2811 - auc: 0.5976 - categorical_accuracy: 0.2811 - val_loss: 1.5164 - val_accuracy: 0.3617 - val_auc: 0.6614 - val_categorical_accuracy: 0.3617\n",
      "Epoch 2/25\n",
      "151/151 [==============================] - 400s 3s/step - loss: 1.4964 - accuracy: 0.3430 - auc: 0.6649 - categorical_accuracy: 0.3430 - val_loss: 1.4341 - val_accuracy: 0.3876 - val_auc: 0.7086 - val_categorical_accuracy: 0.3876\n",
      "Epoch 3/25\n",
      "151/151 [==============================] - 358s 2s/step - loss: 1.4576 - accuracy: 0.3693 - auc: 0.6910 - categorical_accuracy: 0.3693 - val_loss: 1.4108 - val_accuracy: 0.4056 - val_auc: 0.7179 - val_categorical_accuracy: 0.4056\n",
      "Epoch 4/25\n",
      "151/151 [==============================] - 352s 2s/step - loss: 1.4329 - accuracy: 0.3933 - auc: 0.7068 - categorical_accuracy: 0.3933 - val_loss: 1.4073 - val_accuracy: 0.4001 - val_auc: 0.7190 - val_categorical_accuracy: 0.4001\n",
      "Epoch 5/25\n",
      "151/151 [==============================] - 356s 2s/step - loss: 1.4133 - accuracy: 0.3969 - auc: 0.7162 - categorical_accuracy: 0.3969 - val_loss: 1.4055 - val_accuracy: 0.4060 - val_auc: 0.7193 - val_categorical_accuracy: 0.4060\n",
      "Epoch 6/25\n",
      "151/151 [==============================] - 357s 2s/step - loss: 1.3889 - accuracy: 0.4087 - auc: 0.7290 - categorical_accuracy: 0.4087 - val_loss: 1.3733 - val_accuracy: 0.4199 - val_auc: 0.7347 - val_categorical_accuracy: 0.4199\n",
      "Epoch 7/25\n",
      "151/151 [==============================] - 358s 2s/step - loss: 1.3700 - accuracy: 0.4216 - auc: 0.7374 - categorical_accuracy: 0.4216 - val_loss: 1.3865 - val_accuracy: 0.4187 - val_auc: 0.7328 - val_categorical_accuracy: 0.4187\n",
      "Epoch 8/25\n",
      "151/151 [==============================] - 351s 2s/step - loss: 1.3562 - accuracy: 0.4261 - auc: 0.7443 - categorical_accuracy: 0.4261 - val_loss: 1.3409 - val_accuracy: 0.4339 - val_auc: 0.7496 - val_categorical_accuracy: 0.4339\n",
      "Epoch 9/25\n",
      "151/151 [==============================] - 357s 2s/step - loss: 1.3355 - accuracy: 0.4362 - auc: 0.7538 - categorical_accuracy: 0.4362 - val_loss: 1.3308 - val_accuracy: 0.4380 - val_auc: 0.7538 - val_categorical_accuracy: 0.4380\n",
      "Epoch 10/25\n",
      "151/151 [==============================] - 358s 2s/step - loss: 1.3093 - accuracy: 0.4458 - auc: 0.7660 - categorical_accuracy: 0.4458 - val_loss: 1.3311 - val_accuracy: 0.4406 - val_auc: 0.7539 - val_categorical_accuracy: 0.4406\n",
      "Epoch 11/25\n",
      "151/151 [==============================] - 351s 2s/step - loss: 1.2864 - accuracy: 0.4554 - auc: 0.7740 - categorical_accuracy: 0.4554 - val_loss: 1.3372 - val_accuracy: 0.4347 - val_auc: 0.7525 - val_categorical_accuracy: 0.4347\n",
      "Epoch 12/25\n",
      "151/151 [==============================] - 359s 2s/step - loss: 1.2684 - accuracy: 0.4649 - auc: 0.7831 - categorical_accuracy: 0.4649 - val_loss: 1.3213 - val_accuracy: 0.4400 - val_auc: 0.7582 - val_categorical_accuracy: 0.4400\n",
      "Epoch 13/25\n",
      "151/151 [==============================] - 280s 2s/step - loss: 1.2403 - accuracy: 0.4748 - auc: 0.7929 - categorical_accuracy: 0.4748 - val_loss: 1.3259 - val_accuracy: 0.4403 - val_auc: 0.7574 - val_categorical_accuracy: 0.4403\n",
      "Epoch 14/25\n",
      "151/151 [==============================] - 127s 844ms/step - loss: 1.2262 - accuracy: 0.4837 - auc: 0.7983 - categorical_accuracy: 0.4837 - val_loss: 1.3404 - val_accuracy: 0.4369 - val_auc: 0.7517 - val_categorical_accuracy: 0.4369\n",
      "Epoch 15/25\n",
      "151/151 [==============================] - 132s 874ms/step - loss: 1.2062 - accuracy: 0.4866 - auc: 0.8039 - categorical_accuracy: 0.4866 - val_loss: 1.3256 - val_accuracy: 0.4521 - val_auc: 0.7608 - val_categorical_accuracy: 0.4521\n",
      "Epoch 16/25\n",
      "151/151 [==============================] - 132s 873ms/step - loss: 1.1831 - accuracy: 0.4989 - auc: 0.8132 - categorical_accuracy: 0.4989 - val_loss: 1.3407 - val_accuracy: 0.4449 - val_auc: 0.7594 - val_categorical_accuracy: 0.4449\n",
      "Epoch 17/25\n",
      "151/151 [==============================] - 126s 834ms/step - loss: 1.1545 - accuracy: 0.5081 - auc: 0.8224 - categorical_accuracy: 0.5081 - val_loss: 1.3237 - val_accuracy: 0.4411 - val_auc: 0.7596 - val_categorical_accuracy: 0.4411\n",
      "Epoch 18/25\n",
      "151/151 [==============================] - 129s 855ms/step - loss: 1.1483 - accuracy: 0.5105 - auc: 0.8247 - categorical_accuracy: 0.5105 - val_loss: 1.3494 - val_accuracy: 0.4387 - val_auc: 0.7569 - val_categorical_accuracy: 0.4387\n",
      "Epoch 19/25\n",
      "151/151 [==============================] - 157s 1s/step - loss: 1.1240 - accuracy: 0.5211 - auc: 0.8325 - categorical_accuracy: 0.5211 - val_loss: 1.3418 - val_accuracy: 0.4426 - val_auc: 0.7585 - val_categorical_accuracy: 0.4426\n",
      "Epoch 20/25\n",
      "151/151 [==============================] - 140s 930ms/step - loss: 1.1028 - accuracy: 0.5311 - auc: 0.8392 - categorical_accuracy: 0.5311 - val_loss: 1.3486 - val_accuracy: 0.4463 - val_auc: 0.7605 - val_categorical_accuracy: 0.4463\n",
      "Epoch 21/25\n",
      "151/151 [==============================] - 147s 976ms/step - loss: 1.0882 - accuracy: 0.5324 - auc: 0.8436 - categorical_accuracy: 0.5324 - val_loss: 1.3747 - val_accuracy: 0.4399 - val_auc: 0.7572 - val_categorical_accuracy: 0.4399\n",
      "Epoch 22/25\n",
      "151/151 [==============================] - 141s 933ms/step - loss: 1.0609 - accuracy: 0.5488 - auc: 0.8521 - categorical_accuracy: 0.5488 - val_loss: 1.3724 - val_accuracy: 0.4417 - val_auc: 0.7556 - val_categorical_accuracy: 0.4417\n",
      "Epoch 23/25\n",
      "151/151 [==============================] - 150s 996ms/step - loss: 1.0365 - accuracy: 0.5481 - auc: 0.8587 - categorical_accuracy: 0.5481 - val_loss: 1.3861 - val_accuracy: 0.4400 - val_auc: 0.7602 - val_categorical_accuracy: 0.4400\n",
      "Epoch 24/25\n",
      "151/151 [==============================] - 140s 927ms/step - loss: 1.0195 - accuracy: 0.5652 - auc: 0.8637 - categorical_accuracy: 0.5652 - val_loss: 1.3953 - val_accuracy: 0.4326 - val_auc: 0.7513 - val_categorical_accuracy: 0.4326\n",
      "Epoch 25/25\n",
      "151/151 [==============================] - 133s 879ms/step - loss: 1.0147 - accuracy: 0.5646 - auc: 0.8649 - categorical_accuracy: 0.5646 - val_loss: 1.3971 - val_accuracy: 0.4343 - val_auc: 0.7536 - val_categorical_accuracy: 0.4343\n"
     ]
    }
   ],
   "source": [
    "model_adam_age = tf.keras.Sequential()\n",
    "\n",
    "# Primera capa de la CNN. El imput debe ajsutarse al tamañ ode la imagen (32 x 32 y 3 de los colores)\n",
    "\n",
    "# aumentamos los filters a 256 y el kernel l obajamos a 2 debido a que la edad es más dificil de predecir\n",
    "\n",
    "model_adam_age.add(tf.keras.layers.Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3))) \n",
    "model_adam_age.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_adam_age.add(tf.keras.layers.Dropout(0.3))\n",
    "model_adam_age.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "model_adam_age.add(tf.keras.layers.Conv2D(filters=256, kernel_size=2, padding='same', activation='relu')) \n",
    "model_adam_age.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_adam_age.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_adam_age.add(tf.keras.layers.Flatten())\n",
    "model_adam_age.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model_adam_age.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model_adam_age.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model_adam_age.summary()\n",
    "\n",
    "model_adam_age.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy','AUC','categorical_accuracy'])\n",
    "\n",
    "h_model_adam_age = model_adam_age.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=100,\n",
    "         epochs=25,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adam_age_history = h_model_adam_age.history\n",
    "json.dump(model_adam_age_history, open(\"../models/model_adam_age_history.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/model_adam_age.h\\assets\n"
     ]
    }
   ],
   "source": [
    "model_adam_age.save('../models/model_adam_age.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
